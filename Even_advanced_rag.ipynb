{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa024fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aff3ecd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the environment variables from a .env file\n",
    "load_dotenv()\n",
    "\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_REGION = os.getenv(\"PINECONE_REGION\")\n",
    "PINECONE_CLOUD = os.getenv(\"PINECONE_CLOUD\")\n",
    "HUGGING_FACE_API = os.getenv(\"HUGGING_FACE_API\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8c539e",
   "metadata": {},
   "source": [
    "# Data Pipeline / Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3e97e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, Document, VectorStoreIndex\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core.node_parser import SemanticSplitterNodeParser\n",
    "from huggingface_hub import InferenceClient\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8182a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\"data\", required_exts=[\".pdf\"]).load_data()\n",
    "\n",
    "# Combine all pages into one big document\n",
    "combined_text = \"\\n\\n\".join([doc.text for doc in documents])\n",
    "combined_doc = Document(text=combined_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c8e86cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 256 documents from the 'data' directory.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "AN\tIMPRINT\tOF\tPENGUIN\tRANDOM\tHOUSE\tLLC\n",
      "375\tHudson\tStreet\n",
      "New\tYork,\tNew\tYork\t10014\n",
      "Copyright\t©\t2018\tby\tJames\tClear\n",
      "Penguin\tsupports\tcopyright.\tCopyright\tfuels\tcreativity,\tencourages\tdiverse\tvoices,\tpromotes\tfree\tspeech,\tand\tcreates\ta\tvibrant\tculture.\tThank\tyou\tfor\tbuying\tan\tauthorized\tedition\tof\tthis\tbook\tand\tfor\n",
      "complying\twith\tcopyright\tlaws\tby\tnot\treproducing,\tscanning,\tor\tdistributing\tany\tpart\tof\tit\tin\tany\tform\twithout\tpermission.\tYou\tare\tsupporting\twriters\tand\tallowing\tPenguin\tto\tcontinue\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loaded {len(documents)} documents from the 'data' directory.\\n\\n\")\n",
    "print(combined_doc.text[:500])  # First 500 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f26f9879",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = HuggingFaceEmbedding(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6882a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = SemanticSplitterNodeParser.from_defaults(\n",
    "    embed_model=embed_model,\n",
    "    buffer_size=3,\n",
    "    breakpoint_percentile_threshold=90,\n",
    "    include_metadata=True,\n",
    "    include_prev_next_rel=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4baed301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 767 semantic nodes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nodes = splitter.get_nodes_from_documents(documents)\n",
    "print(f\"Created {len(nodes)} semantic nodes\")\n",
    "print(nodes[0].text[:300])  # View first chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "039c945e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIGURE\t3:\tThere\tare\tthree\tlayers\tof\tbehavior\tchange:\ta\tchange\tin\tyour\toutcomes,\ta\tchange\tin\tyour\tprocesses,\tor\ta\tchange\tin\tyour\tidentity.\n",
      "The\tfirst\tlayer\tis\tchanging\tyour\toutcomes.\n",
      "\tThis\tlevel\tis\tconcerned\twith\n",
      "changing\t your\t results:\t losing\t weight,\t publishing\t a\t book,\t winning\t a\n",
      "championship.\tMost\tof\tthe\tgoals\tyou\tset\tare\tassociated\twith\tthis\tlevel\tof\tchange.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(nodes[80].text[:500])  # First 500 characters of the first node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91af1668",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.vector_stores.pinecone import PineconeVectorStore\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.retrievers.bm25 import BM25Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da285cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "index_name = \"rag-llamaindex\"\n",
    "embedding_dim = 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "346b828d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create index if it doesn't exist\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=embedding_dim,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=PINECONE_CLOUD,\n",
    "            region=PINECONE_REGION\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00a019a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the Pinecone index\n",
    "pinecone_index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69d4aee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LlamaIndex Pinecone vector store wrapper\n",
    "vector_store = PineconeVectorStore(pinecone_index=pinecone_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a82c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create index that USES Pinecone\n",
    "index = VectorStoreIndex(\n",
    "    nodes, \n",
    "    vector_store=vector_store,  # ← This stores in Pinecone!\n",
    "    embed_model=embed_model\n",
    ")\n",
    "\n",
    "# Add nodes to Pinecone\n",
    "vector_store.add_nodes(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6536f6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f06818",
   "metadata": {},
   "source": [
    "#### Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "87442121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize reranker model\n",
    "reranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-2-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ee3382d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank_results(query, results, top_k=5):\n",
    "    \"\"\"Rerank retrieved results for better quality\"\"\"\n",
    "    \n",
    "    # Prepare query-document pairs for reranking\n",
    "    query_doc_pairs = []\n",
    "    for result in results:\n",
    "        query_doc_pairs.append([query, result.node.text])\n",
    "    \n",
    "    # Get reranking scores\n",
    "    rerank_scores = reranker.predict(query_doc_pairs)\n",
    "    \n",
    "    # Combine original results with new scores\n",
    "    reranked_results = []\n",
    "    for i, result in enumerate(results):\n",
    "        # Create new result with reranking score\n",
    "        result.score = rerank_scores[i]  # Update with rerank score\n",
    "        reranked_results.append(result)\n",
    "    \n",
    "    # Sort by rerank score (higher is better)\n",
    "    reranked_results.sort(key=lambda x: x.score, reverse=True)\n",
    "    \n",
    "    return reranked_results[:top_k]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ce936a",
   "metadata": {},
   "source": [
    "# Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f55b870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Modified retrieval with reranking\n",
    "# user_question = \"Summarize this book\"\n",
    "\n",
    "# # Step 1: Get vector retriever\n",
    "# vector_retriever = index.as_retriever(similarity_top_k=10)\n",
    "\n",
    "# # Step 2: Create query fusion retriever combining vector and BM25\n",
    "# fusion_retriever = QueryFusionRetriever(\n",
    "#     retrievers=[vector_retriever, bm25_retriever],\n",
    "#     similarity_top_k=20,  # Get 20 candidates from fusion\n",
    "#     num_queries=1,        # Use original query\n",
    "#     use_async=False\n",
    "# )\n",
    "\n",
    "# # Step 3: Retrieve using fusion (combines vector + BM25)\n",
    "# fusion_results = fusion_retriever.retrieve(user_question)\n",
    "\n",
    "# print(f\"Retrieved {len(fusion_results)} results from fusion retriever\")\n",
    "\n",
    "# # Step 4: Rerank the fused results\n",
    "# reranked_results = rerank_results(user_question, fusion_results, top_k=5)\n",
    "\n",
    "# # Step 3: Build context with reranked results\n",
    "# context_blocks = []\n",
    "# for i, node_with_score in enumerate(reranked_results):\n",
    "#     node = node_with_score.node\n",
    "    \n",
    "#     block = f\"\"\"\n",
    "# --- Excerpt {i+1} (Rerank Score: {node_with_score.score:.3f}) ---\n",
    "# {node.text}\n",
    "# \"\"\"\n",
    "#     context_blocks.append(block)\n",
    "\n",
    "# retrieved_text = \"\\n\".join(context_blocks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5a3ba38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create BM25 retriever (sparse vectors)\n",
    "bm25_retriever = BM25Retriever.from_defaults(\n",
    "    nodes=nodes,  # Nodes created from your documents\n",
    "    similarity_top_k=10  # Top 10 sparse results\n",
    ")\n",
    "\n",
    "# Step 2: Create dense vector retriever\n",
    "vector_retriever = VectorIndexRetriever(\n",
    "    index=index,  # Your Pinecone-backed index\n",
    "    similarity_top_k=10  # Top 10 dense results\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "56ff2372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Manual hybrid retrieval (no LLM needed)\n",
    "def hybrid_retrieve(query, vector_retriever, bm25_retriever, top_k=20):\n",
    "    \"\"\"Manually combine vector and BM25 results\"\"\"\n",
    "    \n",
    "    # Get results from both retrievers\n",
    "    vector_results = vector_retriever.retrieve(query)\n",
    "    bm25_results = bm25_retriever.retrieve(query)\n",
    "    \n",
    "    # Combine and deduplicate by node ID\n",
    "    all_results = []\n",
    "    seen_node_ids = set()\n",
    "    \n",
    "    # Add vector results\n",
    "    for result in vector_results:\n",
    "        if result.node.node_id not in seen_node_ids:\n",
    "            all_results.append(result)\n",
    "            seen_node_ids.add(result.node.node_id)\n",
    "    \n",
    "    # Add BM25 results (skip duplicates)\n",
    "    for result in bm25_results:\n",
    "        if result.node.node_id not in seen_node_ids:\n",
    "            all_results.append(result)\n",
    "            seen_node_ids.add(result.node.node_id)\n",
    "    \n",
    "    # Sort by score and return top_k\n",
    "    all_results.sort(key=lambda x: x.score, reverse=True)\n",
    "    return all_results[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14a98a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 20 results using hybrid retrieval.\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Retrieve results using hybrid retriever\n",
    "user_question = \"Who won the Ballon d'Or in 2023, according to Atomic Habits?\"\n",
    "hybrid_results = hybrid_retrieve(user_question, vector_retriever, bm25_retriever, top_k=20)\n",
    "print(f\"Retrieved {len(hybrid_results)} results using hybrid retrieval.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1cca44cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Rerank hybrid results\n",
    "reranked_results = rerank_results(user_question, hybrid_results, top_k=5)\n",
    "\n",
    "# Step 6: Build context with reranked results\n",
    "context_blocks = []\n",
    "for i, node_with_score in enumerate(reranked_results):\n",
    "    node = node_with_score.node\n",
    "    block = f\"\"\"\n",
    "--- Excerpt {i+1} (Rerank Score: {node_with_score.score:.3f}) ---\n",
    "{node.text}\n",
    "\"\"\"\n",
    "    context_blocks.append(block)\n",
    "\n",
    "retrieved_text = \"\\n\".join(context_blocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617accb9",
   "metadata": {},
   "source": [
    "# Generateion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b164d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can only discuss content from this book. Please ask me about topics, concepts, or themes covered in \"The Surprising Power of Atomic Habits.\" The excerpts provided do not mention anything about the Ballon d'Or or its winner in 2023. If you have questions about the principles or ideas from the book, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Final prompt\n",
    "prompt = f\"Context:\\n{retrieved_text}\\n\\nQuestion: {user_question}\\nAnswer:\"\n",
    "\n",
    "\n",
    "client = InferenceClient(\n",
    "    provider=\"auto\",\n",
    "    api_key=os.getenv(\"HUGGING_FACE_API\"),\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"microsoft/phi-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"\"\"You are a specialized Book Analysis Assistant.\n",
    "\n",
    "CAPABILITIES:\n",
    "- Provide comprehensive book summaries and chapter overviews\n",
    "- Answer questions about specific concepts, themes, and ideas from the book\n",
    "- Explain key principles and their practical applications\n",
    "- Compare different concepts within the book\n",
    "- Provide relevant quotes and examples from the text\n",
    "- Offer detailed analysis of characters, plot, or arguments (depending on book type)\n",
    "- Generate thoughtful book reviews and critical analysis\n",
    "- Discuss the book's relevance and impact\n",
    "\n",
    "STRICT GUIDELINES:\n",
    "1. ONLY use information from the provided context below\n",
    "2. If asked about topics outside this specific book, respond: \"I can only discuss content from this book. Please ask me about topics, concepts, or themes covered in this book.\"\n",
    "3. If asked about other books, authors, or general topics, politely redirect to this book's content\n",
    "4. Be comprehensive but focused in your responses\n",
    "5. Include specific examples, quotes, and page references when available in context\n",
    "6. Structure answers clearly with headings or bullet points for complex topics\n",
    "\n",
    "RESPONSE STRUCTURE:\n",
    "- Direct answer to the question\n",
    "- Supporting evidence from the book\n",
    "- Relevant examples or case studies from the text  \n",
    "- Practical implications or takeaways when applicable\n",
    "- Clear indication if context is insufficient for a complete answer\n",
    "\n",
    "TONE: Professional, knowledgeable, and helpful while staying strictly within the book's scope.\"\"\"\n",
    "},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253b1dd7",
   "metadata": {},
   "source": [
    "# Performance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d944d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COMPARISON OF RETRIEVAL METHODS ===\n",
      "\n",
      "Vector Search Only: 10 results\n",
      "Top result score: 0.507\n",
      "Sample result: Acknowledgments\n",
      "I\n",
      "\t\n",
      "HAVE\tRELIED\tHEAVILY\t\n",
      "on\tothers\tduring\tthe\tcreation\tof\tthis\tbook.\tBefore\tanyone\telse,\tI\n",
      "must\tthank\tmy\twife,\tKristy,\twho\thas\tbeen\tin...\n",
      "\n",
      "BM25 Only: 10 results\n",
      "Top result score: 1.670\n",
      "Sample result: She\n",
      "gave\tme\tthe\tspace\tI\tneeded\tto\tcreate\ta\tbook\tI\twas\tproud\tof\tand\tchampioned\tmy\n",
      "ideas\tat\tevery\tstep.\tTo\tNina,\tfor\ther\tability\tto\ttransform\tmy\twriting...\n",
      "\n",
      "Hybrid (Vector + BM25): 16 results\n",
      "Top result score: -8.847\n",
      "Sample result: *\n",
      "\tReaders\tof\n",
      "\tThe\tPower\tof\tHabit\n",
      "\tby\tCharles\tDuhigg\twill\trecognize\tthese\tterms.\n",
      "Duhigg\twrote\ta\tgreat\tbook\tand\tmy\tintention\tis\tto\tpick\tup\twhere\the\tlef...\n",
      "\n",
      "Final Reranked: 5 results\n",
      "Top result score: -7.331\n",
      "Sample result: Acknowledgments\n",
      "I\n",
      "\t\n",
      "HAVE\tRELIED\tHEAVILY\t\n",
      "on\tothers\tduring\tthe\tcreation\tof\tthis\tbook.\tBefore\tanyone\telse,\tI\n",
      "must\tthank\tmy\twife,\tKristy,\twho\thas\tbeen\tin...\n",
      "\n",
      "=== SUMMARY ===\n",
      "Question: 'Summarize this book'\n",
      "Vector retrieval found 10 results\n",
      "BM25 retrieval found 10 results\n",
      "Hybrid retrieval combined to 16 unique results\n",
      "Final reranking selected top 5 most relevant results\n"
     ]
    }
   ],
   "source": [
    "# Optional: Compare different retrieval methods\n",
    "print(\"=== COMPARISON OF RETRIEVAL METHODS ===\\n\")\n",
    "\n",
    "# Vector only\n",
    "vector_only = vector_retriever.retrieve(user_question)\n",
    "print(f\"Vector Search Only: {len(vector_only)} results\")\n",
    "print(f\"Top result score: {vector_only[0].score:.3f}\")\n",
    "print(f\"Sample result: {vector_only[0].node.text[:150]}...\\n\")\n",
    "\n",
    "# BM25 only  \n",
    "bm25_only = bm25_retriever.retrieve(user_question)\n",
    "print(f\"BM25 Only: {len(bm25_only)} results\")\n",
    "print(f\"Top result score: {bm25_only[0].score:.3f}\")\n",
    "print(f\"Sample result: {bm25_only[0].node.text[:150]}...\\n\")\n",
    "\n",
    "# Hybrid (Vector + BM25)\n",
    "print(f\"Hybrid (Vector + BM25): {len(hybrid_results)} results\")\n",
    "print(f\"Top result score: {hybrid_results[0].score:.3f}\")\n",
    "print(f\"Sample result: {hybrid_results[0].node.text[:150]}...\\n\")\n",
    "\n",
    "# Final reranked\n",
    "print(f\"Final Reranked: {len(reranked_results)} results\")\n",
    "print(f\"Top result score: {reranked_results[0].score:.3f}\")\n",
    "print(f\"Sample result: {reranked_results[0].node.text[:150]}...\\n\")\n",
    "\n",
    "print(\"=== SUMMARY ===\")\n",
    "print(f\"Question: '{user_question}'\")\n",
    "print(f\"Vector retrieval found {len(vector_only)} results\")\n",
    "print(f\"BM25 retrieval found {len(bm25_only)} results\") \n",
    "print(f\"Hybrid retrieval combined to {len(hybrid_results)} unique results\")\n",
    "print(f\"Final reranking selected top {len(reranked_results)} most relevant results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7212295",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8981a538",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/test_queries.csv\", delimiter=\"\\t\")  # For tab-separated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9f8417af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can you use Atomic Habits to invest in the sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the Goldilocks Rule in Atomic Habits?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How does the book connect habits with long-ter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Can I learn how to code in Python from Atomic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How does feedback reinforce or hinder habits?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question\n",
       "0  Can you use Atomic Habits to invest in the sto...\n",
       "1      What is the Goldilocks Rule in Atomic Habits?\n",
       "2  How does the book connect habits with long-ter...\n",
       "3  Can I learn how to code in Python from Atomic ...\n",
       "4      How does feedback reinforce or hinder habits?"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "01ea4763",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = data[\"question\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d7639923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Can you use Atomic Habits to invest in the stock market?',\n",
       " 'What is the Goldilocks Rule in Atomic Habits?',\n",
       " 'How does the book connect habits with long-term success?',\n",
       " 'Can I learn how to code in Python from Atomic Habits?',\n",
       " 'How does feedback reinforce or hinder habits?',\n",
       " 'What role does identity play in habit formation?',\n",
       " 'What are some limitations of the habit strategies in the book?',\n",
       " 'What’s the significance of the plateau of latent potential?',\n",
       " 'Can I use Atomic Habits to invest in the stock market?',\n",
       " 'What are the four laws of behavior change according to Atomic Habits?',\n",
       " 'How can friction be used to eliminate bad habits?',\n",
       " 'Does the book include a workout plan for bodybuilding?',\n",
       " 'How can someone recover from a habit relapse?',\n",
       " 'Does Atomic Habits talk about AI or machine learning?',\n",
       " 'What psychological theories support the habit loop in Atomic Habits?',\n",
       " 'How do small habits compound over time?',\n",
       " 'What are the top 10 tourist places in Japan mentioned in Atomic Habits?',\n",
       " 'What is the 1% improvement principle?',\n",
       " 'How does delayed gratification relate to habit building?',\n",
       " 'Why is focusing on identity change more effective than goal setting?',\n",
       " 'Does Atomic Habits work for people with ADHD?',\n",
       " 'How does Atomic Habits relate to the concept of neuroplasticity?',\n",
       " 'What are some practical ways to make habits more attractive?',\n",
       " 'What is temptation bundling and how does it work?',\n",
       " 'What does Atomic Habits say about the history of Nepal?',\n",
       " 'What examples does the book give to illustrate habit tracking?',\n",
       " 'How do habits influence workplace productivity?',\n",
       " 'How does visualization support habit formation?',\n",
       " 'Does Atomic Habits provide a recipe for chicken curry?',\n",
       " 'Is there a difference between routines and habits?',\n",
       " 'How does the environment influence our habits?',\n",
       " \"Who won the Ballon d'Or in 2023, according to Atomic Habits?\",\n",
       " 'What does James Clear say about willpower and motivation?',\n",
       " 'What role does community play in sustaining habits?',\n",
       " 'How can one use cues to trigger good habits?',\n",
       " 'How does James Clear define a habit?',\n",
       " 'How do small habits compound over time?',\n",
       " 'Is there a chapter about UFO sightings in Atomic Habits?',\n",
       " 'How does Atomic Habits differentiate between goals and systems?',\n",
       " 'How can I use cues to trigger good habits?',\n",
       " 'How can someone recover from a habit relapse?',\n",
       " 'What habits does James Clear personally follow?',\n",
       " 'What is the 1% improvement principle?',\n",
       " 'Can you summarize the habit loop as explained in Atomic Habits?',\n",
       " 'How does James Clear compare his ideas to Charles Duhigg’s The Power of Habit?',\n",
       " 'How can friction be used to eliminate bad habits?',\n",
       " 'How do small habits compound over time?',\n",
       " 'What does the book say about habit journaling?',\n",
       " 'Are there any criticisms of Atomic Habits mentioned in the book?',\n",
       " 'What methods are recommended for habit tracking?',\n",
       " 'Explain the concept of habit stacking.']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "982cf063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Q0: Can you use Atomic Habits to invest in the stock market?\n",
      "Processing Q1: What is the Goldilocks Rule in Atomic Habits?\n",
      "Processing Q2: How does the book connect habits with long-term success?\n",
      "Processing Q3: Can I learn how to code in Python from Atomic Habits?\n",
      "Processing Q4: How does feedback reinforce or hinder habits?\n",
      "Processing Q5: What role does identity play in habit formation?\n",
      "Processing Q6: What are some limitations of the habit strategies in the book?\n",
      "Processing Q7: What’s the significance of the plateau of latent potential?\n",
      "Processing Q8: Can I use Atomic Habits to invest in the stock market?\n",
      "Processing Q9: What are the four laws of behavior change according to Atomic Habits?\n",
      "Processing Q10: How can friction be used to eliminate bad habits?\n",
      "Processing Q11: Does the book include a workout plan for bodybuilding?\n",
      "Processing Q12: How can someone recover from a habit relapse?\n",
      "Processing Q13: Does Atomic Habits talk about AI or machine learning?\n",
      "Processing Q14: What psychological theories support the habit loop in Atomic Habits?\n",
      "Processing Q15: How do small habits compound over time?\n",
      "Processing Q16: What are the top 10 tourist places in Japan mentioned in Atomic Habits?\n",
      "Processing Q17: What is the 1% improvement principle?\n",
      "Processing Q18: How does delayed gratification relate to habit building?\n",
      "Processing Q19: Why is focusing on identity change more effective than goal setting?\n",
      "Processing Q20: Does Atomic Habits work for people with ADHD?\n",
      "Processing Q21: How does Atomic Habits relate to the concept of neuroplasticity?\n",
      "Processing Q22: What are some practical ways to make habits more attractive?\n",
      "Processing Q23: What is temptation bundling and how does it work?\n",
      "Processing Q24: What does Atomic Habits say about the history of Nepal?\n",
      "Processing Q25: What examples does the book give to illustrate habit tracking?\n",
      "Processing Q26: How do habits influence workplace productivity?\n",
      "Processing Q27: How does visualization support habit formation?\n",
      "Processing Q28: Does Atomic Habits provide a recipe for chicken curry?\n",
      "Processing Q29: Is there a difference between routines and habits?\n",
      "Processing Q30: How does the environment influence our habits?\n",
      "Processing Q31: Who won the Ballon d'Or in 2023, according to Atomic Habits?\n",
      "Processing Q32: What does James Clear say about willpower and motivation?\n",
      "Processing Q33: What role does community play in sustaining habits?\n",
      "Processing Q34: How can one use cues to trigger good habits?\n",
      "Processing Q35: How does James Clear define a habit?\n",
      "Processing Q36: How do small habits compound over time?\n",
      "Processing Q37: Is there a chapter about UFO sightings in Atomic Habits?\n",
      "Processing Q38: How does Atomic Habits differentiate between goals and systems?\n",
      "Processing Q39: How can I use cues to trigger good habits?\n",
      "Processing Q40: How can someone recover from a habit relapse?\n",
      "Processing Q41: What habits does James Clear personally follow?\n",
      "Processing Q42: What is the 1% improvement principle?\n",
      "Processing Q43: Can you summarize the habit loop as explained in Atomic Habits?\n",
      "Processing Q44: How does James Clear compare his ideas to Charles Duhigg’s The Power of Habit?\n",
      "Processing Q45: How can friction be used to eliminate bad habits?\n",
      "Processing Q46: How do small habits compound over time?\n",
      "Processing Q47: What does the book say about habit journaling?\n",
      "Processing Q48: Are there any criticisms of Atomic Habits mentioned in the book?\n",
      "Processing Q49: What methods are recommended for habit tracking?\n",
      "Processing Q50: Explain the concept of habit stacking.\n",
      "✅ All question scores saved to retrieval_score_results.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def to_native(val):\n",
    "    \"\"\"Convert numpy float types to native Python floats.\"\"\"\n",
    "    if isinstance(val, (np.float32, np.float64)):\n",
    "        return float(val)\n",
    "    return val\n",
    "\n",
    "# Assuming: questions = data[\"question\"].tolist()\n",
    "questions = data[\"question\"].tolist()\n",
    "\n",
    "all_scores = {}\n",
    "\n",
    "for i, question in enumerate(questions):\n",
    "    print(f\"Processing Q{i}: {question}\")\n",
    "\n",
    "    # Retrieve results\n",
    "    sparse_results = bm25_retriever.retrieve(question)\n",
    "    dense_results = vector_retriever.retrieve(question)\n",
    "    hybrid_results = hybrid_retrieve(question, vector_retriever, bm25_retriever)\n",
    "    reranked_results = rerank_results(question, hybrid_results)\n",
    "\n",
    "    # Store scores only\n",
    "    all_scores[f\"q_{i}\"] = {\n",
    "        \"question\": question,\n",
    "        \"sparse_scores\": [to_native(r.score) for r in sparse_results],\n",
    "        \"dense_scores\": [to_native(r.score) for r in dense_results],\n",
    "        \"hybrid_scores\": [to_native(r.score) for r in hybrid_results],\n",
    "        \"reranked_scores\": [to_native(r.score) for r in reranked_results]\n",
    "    }\n",
    "\n",
    "# Save all scores to JSON\n",
    "with open(\"retrieval_score_results.json\", \"w\") as f:\n",
    "    json.dump(all_scores, f, indent=2)\n",
    "\n",
    "print(\"✅ All question scores saved to retrieval_score_results.json\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG-using-LlamaIndex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
