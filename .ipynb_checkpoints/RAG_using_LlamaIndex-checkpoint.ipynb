{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34e46055-4721-40b8-a827-ad606a0994f6",
   "metadata": {},
   "source": [
    "Main Goal: To create a rag system that provides information usin sonnet using shakesphere's sonnet\n",
    "# To-Do\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e5b4a04-6956-40a7-92db-0fb75a1a6c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d019baf-b09a-4f3d-9e55-27f8bd459a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from huggingface_hub import InferenceClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4abb1130-6850-40a1-a0a0-154e5ad8f1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_REGION = os.getenv(\"PINECONE_REGION\")\n",
    "PINECONE_CLOUD = os.getenv(\"PINECONE_CLOUD\")\n",
    "HUGGING_FACE_API = os.getenv(\"HUGGING_FACE_API\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01b0e70b-dc5f-4dc0-aeb3-dff293e7facf",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\"data\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87cf7840-4a3e-4163-ad3c-a819b8b2562e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 documents\n",
      "\n",
      "\n",
      "From fairest creatures we desire increase,\n",
      "That thereby beauty's rose might never die,\n",
      "But as the riper should by time decease,\n",
      "His tender heir might bear his memory:\n",
      "But thou contracted to thine own bright eyes,\n",
      "Feed'st thy light's flame with self-substantial fuel,\n",
      "Making a famine where abundance lies,\n",
      "Thy self thy foe, to thy sweet self too cruel:\n",
      "Thou that art now the world's fresh ornament,\n",
      "And only herald to the gaudy spring,\n",
      "Within thine own bud buriest thy content,\n",
      "And, tender \n"
     ]
    }
   ],
   "source": [
    "print(f\"Loaded {len(documents)} documents\\n\\n\")\n",
    "print(documents[0].text[:500])  # Show a preview of the first doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afcc6e48-0071-4f10-859b-31c40d703298",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = SentenceSplitter(chunk_size=512, chunk_overlap=50)\n",
    "nodes = splitter.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3ba7f01-7d3a-44a9-9ce3-e3db7698b4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TextNode(id_='6d799fdd-5f6d-4478-b15f-dd0d825dd60e', embedding=None, metadata={'file_path': '/home/vertex/Desktop/RAG-using-LlamaIndex/data/Sonnets.txt', 'file_name': 'Sonnets.txt', 'file_type': 'text/plain', 'file_size': 96390, 'creation_date': '2025-07-10', 'last_modified_date': '2025-07-10'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='d3ed3cdf-5e40-4c93-ac41-c1c7210f1d7f', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'file_path': '/home/vertex/Desktop/RAG-using-LlamaIndex/data/Sonnets.txt', 'file_name': 'Sonnets.txt', 'file_type': 'text/plain', 'file_size': 96390, 'creation_date': '2025-07-10', 'last_modified_date': '2025-07-10'}, hash='d2acb3db69fc18a716639cb931dc5c9f53757707801db29cb1543711edcf5650'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8401fb65-0baf-4deb-9e58-003afb6b0f37', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='31f2fb2e056753f45a271aba736468e08ae74335f40217a6c227cf1a9ff94e69')}, metadata_template='{key}: {value}', metadata_separator='\\n', text=\"From fairest creatures we desire increase,\\r\\nThat thereby beauty's rose might never die,\\r\\nBut as the riper should by time decease,\\r\\nHis tender heir might bear his memory:\\r\\nBut thou contracted to thine own bright eyes,\\r\\nFeed'st thy light's flame with self-substantial fuel,\\r\\nMaking a famine where abundance lies,\\r\\nThy self thy foe, to thy sweet self too cruel:\\r\\nThou that art now the world's fresh ornament,\\r\\nAnd only herald to the gaudy spring,\\r\\nWithin thine own bud buriest thy content,\\r\\nAnd, tender churl, mak'st waste in niggarding:\\r\\nPity the world, or else this glutton be,\\r\\nTo eat the world's due, by the grave and thee.\\r\\n\\r\\nWhen forty winters shall besiege thy brow,\\r\\nAnd dig deep trenches in thy beauty's field,\\r\\nThy youth's proud livery so gazed on now,\\r\\nWill be a totter'd weed of small worth held:\\r\\nThen being asked, where all thy beauty lies,\\r\\nWhere all the treasure of thy lusty days;\\r\\nTo say, within thine own deep sunken eyes,\\r\\nWere an all-eating shame, and thriftless praise.\\r\\nHow much more praise deserv'd thy beauty's use,\\r\\nIf thou couldst answer 'This fair child of mine\\r\\nShall sum my count, and make my old excuse,'\\r\\nProving his beauty by succession thine!\\r\\nThis were to be new made when thou art old,\\r\\nAnd see thy blood warm when thou feel'st it cold.\\r\\n\\r\\nLook in thy glass and tell the face thou viewest\\r\\nNow is the time that face should form another;\\r\\nWhose fresh repair if now thou not renewest,\\r\\nThou dost beguile the world, unbless some mother.\\r\\nFor where is she so fair whose uneared womb\\r\\nDisdains the tillage of thy husbandry?\\r\\nOr who is he so fond will be the tomb\\r\\nOf his self-love, to stop posterity?\\r\\nThou art thy mother's glass and she in thee\\r\\nCalls back the lovely April of her prime;\\r\\nSo thou through windows of thine age shalt see,\\r\\nDespite of wrinkles, this thy golden time.\\r\\nBut if thou live, remembered not to be,\\r\\nDie single and thine image dies with thee.\\r\\n\\r\\nUnthrifty loveliness, why dost thou spend\\r\\nUpon thy self thy beauty's legacy?\", mimetype='text/plain', start_char_idx=0, end_char_idx=1975, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}')]\n"
     ]
    }
   ],
   "source": [
    "print(nodes[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b93bb28-fde6-4c5c-9cfd-c2d65ca2af2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec6098cdbd3646b292262f8367f5516c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c93ccbe82a3a404ab9e8850bb720c5fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eae3bf5bcbf4570b5b7c39012f1f136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5221a3bf08142c39277d1f9b47d6e7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a26313a195ee4267b71b5aa52d552e22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4708f174c32d47f7854fece9202802c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31fd687c3c68433a9db73c808c3f3389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10c732f839b64ccdb8a973058ef32b92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4244f43a75ea4bdd821c6fe7f3f18853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb6dd67e57ed493085ea3e77dfd4f900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "545d242df97f4ec5874a5b8511b910a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use HuggingFace embedding model\n",
    "# https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be98079b-5761-4919-909a-56c05b924445",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex(nodes, embed_model=embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cb0822c-61a5-4d22-8284-ae91fff4d79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.vector_stores.pinecone import PineconeVectorStore\n",
    "\n",
    "from pinecone import Pinecone, ServerlessSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38be2f35-ee4a-46d8-9390-3a5b47a08d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "index_name = \"rag-llamaindex\"\n",
    "embedding_dim = 384\n",
    "\n",
    "# Create index if it doesn't exist\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=embedding_dim,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=PINECONE_CLOUD,\n",
    "            region=PINECONE_REGION\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f312c286-b2f2-4e79-bc1e-a58e771f5152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the Pinecone index\n",
    "pinecone_index = pc.Index(index_name)\n",
    "\n",
    "# Create LlamaIndex Pinecone vector store wrapper\n",
    "vector_store = PineconeVectorStore(pinecone_index=pinecone_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "331f42eb-8922-4dfb-b50f-974346e2366b",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex(nodes, embed_model=embed_model, vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "88e13d8c-e3de-4173-8faa-bda7c4ab0f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\"data\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2663f29a-22e9-4502-bf47-4c69d9db8181",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(llm=None)\n",
    "response = query_engine.query(\"What is this document about?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68191663-05b4-437d-909b-8d592451e4e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'VectorStoreIndex' object has no attribute 'query'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is this document about?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m retrieved_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(response)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'VectorStoreIndex' object has no attribute 'query'"
     ]
    }
   ],
   "source": [
    "response = index.query(\"What is this document about?\")\n",
    "retrieved_text = str(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea174e1f-50d1-420c-94c1-dcc2bc08e06f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'retrieved_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m user_question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat does Krishna say about Bhagavad Gita?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Build prompt combining retrieved info + user question\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContext: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mretrieved_text\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mQuestion: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_question\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAnswer:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m completion \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     14\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmicrosoft/phi-4\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     15\u001b[0m     messages\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     ],\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(completion\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'retrieved_text' is not defined"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "client = InferenceClient(\n",
    "    provider=\"auto\",\n",
    "    api_key=HUGGING_FACE_API,\n",
    ")\n",
    "\n",
    "user_question = \"What does Krishna say about Bhagavad Gita?\"\n",
    "\n",
    "# Build prompt combining retrieved info + user question\n",
    "prompt = f\"Context: {retrieved_text}\\n\\nQuestion: {user_question}\\nAnswer:\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"microsoft/phi-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad2cab9-c51a-4c7d-9bf9-d3880ade290b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
